# joongna_seoul_crawler.py
# -*- coding: utf-8 -*-

import re
import csv
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional

from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import argparse


BASE_URL = "https://web.joongna.com"

############################################################
# 0. ì„œìš¸ 25ê°œ êµ¬, ì¹´í…Œê³ ë¦¬ ë§µ
############################################################

SEOUL_DISTRICTS = [
    "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬",
    "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
    "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬",
    "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
    "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬",
    "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬",
]

CATEGORY_MAP = {
    "ì•„ì´í°": 1,
    "ì•„ì´íŒ¨ë“œ": 2,
    "ë§¥ë¶": 3,
    "ì• í”Œì›Œì¹˜": 4,
    "ì—ì–´íŒŸ": 5,
}

IPHONE, IPAD, MACBOOK, APPLE_WATCH, AIRPODS = 1, 2, 3, 4, 5


############################################################
# 1. ê´‘ê³  í•„í„° (ì‚½ë‹ˆë‹¤ / ìˆ˜ë¦¬ ë“±)
############################################################

BUYING_HINTS = [
    "ì‚½ë‹ˆë‹¤", "êµ¬ë§¤í•©ë‹ˆë‹¤", "êµ¬í•´ìš”", "ì°¾ìŠµë‹ˆë‹¤",
    "ë§¤ì…", "ê³ ê°€ë§¤ì…", "ìµœê³ ê°€ë§¤ì…", "ë‹¹ì¼ë§¤ì…",
    "ë§¤ì…í•´ìš”", "ë§¤ì…í•©ë‹ˆë‹¤", "ê³ ê°€ë§¤ìˆ˜",
]

SERVICE_HINTS = [
    "ìˆ˜ë¦¬", "êµì²´", "ìˆ˜ì„ ", "ì¶œì¥ìˆ˜ë¦¬", "ì‚¬ì„¤ìˆ˜ë¦¬",
    "ìœ„íƒíŒë§¤", "ëŒ€ì—¬", "ë Œíƒˆ", "ë³´í—˜", "as", "a/s",
]


def is_advertisement(title: str) -> bool:
    t = title.lower().replace(" ", "")
    if any(k.replace(" ", "") in t for k in BUYING_HINTS):
        return True
    if any(k.replace(" ", "") in t for k in SERVICE_HINTS):
        return True
    return False


############################################################
# 2. ì•¡ì„¸ì„œë¦¬ í•„í„° ê´€ë ¨ ìœ í‹¸
############################################################

def _norm(s: str) -> str:
    return re.sub(r"\s+", "", (s or "")).lower()


def _contains_any(text: str, keywords: List[str]) -> bool:
    t = _norm(text)
    return any(_norm(kw) in t for kw in keywords)


ACCESSORY_CORE: Dict[int, List[str]] = {
    IPHONE: ["ì¼€ì´ìŠ¤", "ë²”í¼", "ì ¤ë¦¬", "ì‹¤ë¦¬ì½˜", "í•„ë¦„", "ë³´í˜¸í•„ë¦„", "ê°•í™”ìœ ë¦¬", "ê±°ì¹˜ëŒ€", "ìŠ¤íƒ ë“œ",
             "íŒì†Œì¼“", "ë§", "ìŠ¤íŠ¸ë©", "ì¶©ì „ê¸°", "ì¼€ì´ë¸”", "ë¼ì´íŠ¸ë‹", "type-c", "ì–´ëŒ‘í„°", "ë°°í„°ë¦¬íŒ©",
             "ë³´ì¡°ë°°í„°ë¦¬", "ë¬´ì„ ì¶©ì „ê¸°", "ë„í‚¹", "ë„í‚¹ìŠ¤í…Œì´ì…˜", "magsafe case", "magnetic case",
             "case", "bumper", "jelly", "silicone", "film", "protector", "screen protector",
             "holder", "dock", "charger", "cable", "adapter"],
    IPAD: ["ì¼€ì´ìŠ¤", "ì»¤ë²„", "ìŠ¤ë§ˆíŠ¸ì»¤ë²„", "í´ë¦¬ì˜¤", "í‚¤ë³´ë“œì¼€ì´ìŠ¤", "í‚¤ë³´ë“œ", "íœìŠ¬íŒ", "íœì´‰",
           "í•„ë¦„", "ê°•í™”ìœ ë¦¬", "ê±°ì¹˜ëŒ€", "ìŠ¤íƒ ë“œ", "í¬ë˜ë“¤", "ì¶©ì „ê¸°", "ì¼€ì´ë¸”", "paperlike",
           "smart cover", "folio", "pencil tip", "holder", "dock", "stand", "charger"],
    MACBOOK: ["íŒŒìš°ì¹˜", "ìŠ¬ë¦¬ë¸Œ", "ì¼€ì´ìŠ¤", "í•˜ë“œì¼€ì´ìŠ¤", "í‚¤ìŠ¤í‚¨", "í‚¤ë³´ë“œ ìŠ¤í‚¨", "í‚¤ìº¡", "í•„ë¦„",
              "ê°•í™”ìœ ë¦¬", "ìŠ¤íƒ ë“œ", "ê±°ì¹˜ëŒ€", "ë…", "í—ˆë¸Œ", "usb í—ˆë¸Œ", "type-c í—ˆë¸Œ", "ë„í‚¹ìŠ¤í…Œì´ì…˜",
              "ì–´ëŒ‘í„°", "ì¶©ì „ê¸°", "ì—°ì¥ì¼€ì´ë¸”", "ì¿¨ëŸ¬", "ì¿¨ë§íŒ¨ë“œ", "sleeve", "pouch", "shell case",
              "keyboard cover", "dock", "hub", "adapter", "stand", "cooler"],
    APPLE_WATCH: ["ë°´ë“œ", "ìŠ¤íŠ¸ë©", "ê°€ì£½ë°´ë“œ", "ë©”íƒˆë°´ë“œ", "ë‚˜ì´í‚¤ë°´ë“œ", "ì¼€ì´ìŠ¤", "ë²”í¼",
                  "ë³´í˜¸í•„ë¦„", "ê°•í™”ìœ ë¦¬", "ì¶©ì „ê¸°", "ì¶©ì „ë…", "ì¶©ì „ìŠ¤íƒ ë“œ", "band", "strap", "loop",
                  "link", "case", "bumper", "film", "charger", "dock", "stand"],
    AIRPODS: ["ì¼€ì´ìŠ¤", "ì‹¤ë¦¬ì½˜ì¼€ì´ìŠ¤", "í•˜ë“œì¼€ì´ìŠ¤", "ê°€ì£½ì¼€ì´ìŠ¤", "í‚¤ë§", "ì´ì–´íŒ", "í¼íŒ",
              "ìŠ¤íŠ¸ë©", "ì¶©ì „ê¸°", "ì¶©ì „ì¼€ì´ë¸”", "ì¶©ì „ì¼€ì´ìŠ¤(ë¹ˆ ì¼€ì´ìŠ¤)", "ë³´í˜¸í•„ë¦„",
              "case", "tip", "ear tip", "foam tip", "strap", "charger"],
}

DEVICE_STRONG_HINTS: Dict[int, List[str]] = {
    IPHONE: ["ë³¸ì²´", "í’€ë°•ìŠ¤", "ì˜ìˆ˜ì¦", "ìê¸‰ì œ", "ë¯¸ê°œë´‰", "ë¦¬í¼", "ê³µê¸°ê³„", "ì •í’ˆë“±ë¡", "ì•„ì´í´ë¼ìš°ë“œ", "icloud",
             "ë°°í„°ë¦¬ì„±ëŠ¥", "ë°°í„°ë¦¬ ì‚¬ì´í´", "ì‚¬ì´í´", "ê°œí†µ", "ìœ ì‹¬", "ìš©ëŸ‰", "128gb", "256gb", "512gb", "1tb"],
    IPAD: ["ë³¸ì²´", "í’€ë°•ìŠ¤", "ì˜ìˆ˜ì¦", "ìê¸‰ì œ", "ë¯¸ê°œë´‰", "ë¦¬í¼", "wifi", "cellular", "lte",
           "ìš©ëŸ‰", "128gb", "256gb", "512gb", "1tb", "2tb", "11í˜•", "12.9", "10.9", "10.2", "9.7"],
    MACBOOK: ["ë³¸ì²´", "í’€ë°•ìŠ¤", "ì˜ìˆ˜ì¦", "m1", "m2", "m3", "intel", "i5", "i7", "ram", "ssd", "ë°°í„°ë¦¬ ì‚¬ì´í´", "ì‚¬ì´í´",
              "13ì¸ì¹˜", "14ì¸ì¹˜", "15ì¸ì¹˜", "16ì¸ì¹˜"],
    APPLE_WATCH: ["ë³¸ì²´", "í’€ë°•ìŠ¤", "ìš¸íŠ¸ë¼", "se", "gps", "cellular", "ë‚˜ì´í‚¤", "41mm", "45mm", "49mm", "40mm", "44mm",
                  "stainless", "aluminum", "í‹°íƒ€ëŠ„"],
    AIRPODS: ["ë³¸ì²´", "ì¶©ì „ì¼€ì´ìŠ¤ í¬í•¨", "ë¯¸ê°œë´‰", "ì •í’ˆ ë“±ë¡", "ì •í’ˆ ì‹œë¦¬ì–¼", "ì‹œë¦¬ì–¼", "case í¬í•¨"],
}

ACCESSORY_ONLY_HINTS: List[str] = [
    "ì „ìš©", "í˜¸í™˜", "for", "ìš©", "ë‹¨í’ˆ",
    "ì¼€ì´ìŠ¤ë§Œ", "í•„ë¦„ë§Œ", "ìŠ¤íŠ¸ë©ë§Œ", "ë°´ë“œë§Œ", "ì¼€ì´ë¸”ë§Œ",
    "ì¶©ì „ì¼€ì´ìŠ¤ ë‹¨í’ˆ", "ì¶©ì „ê¸°ë§Œ", "í—ˆë¸Œë§Œ", "ë…ë§Œ",
    "stand only", "case only", "band only",
]

INCLUSION_PHRASES: List[str] = [
    "ì¼€ì´ìŠ¤ í¬í•¨", "í•„ë¦„ ë¶€ì°©", "í•„ë¦„ ë¶™ì„", "ì‚¬ì€í’ˆ",
    "ë¤ìœ¼ë¡œ", "ì¦ì •", "ì¼€ì´ìŠ¤ ë“œë¦¼", "í•„ë¦„ ë“œë¦¼",
]


def is_accessory_title(
    title: str,
    category_id: int,
    price: Optional[int] = None,
    baseline_mean: Optional[float] = None,
) -> bool:
    """
    True â†’ ì•¡ì„¸ì„œë¦¬(ì œì™¸) / False â†’ ë³¸ì²´(í†µê³¼)
    """
    if not title:
        return False

    # ì•¡ì„¸ì„œë¦¬ í•µì‹¬ ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ë³¸ì²´
    if not _contains_any(title, ACCESSORY_CORE.get(category_id, [])):
        return False

    # 'ë¤/í¬í•¨' í‘œí˜„ì´ ìˆìœ¼ë©´ ë³¸ì²´ íŒë§¤ ê°€ëŠ¥ì„± â†’ ë³¸ì²´
    if _contains_any(title, INCLUSION_PHRASES):
        return False

    # ì•¡ì„¸ì„œë¦¬-ì „ìš© ì‹ í˜¸ â†’ ê°•í•˜ê²Œ ì•¡ì„¸ì„œë¦¬
    if _contains_any(title, ACCESSORY_ONLY_HINTS):
        return True

    # ë³¸ì²´ ê°•í•œ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ë³¸ì²´
    if _contains_any(title, DEVICE_STRONG_HINTS.get(category_id, [])):
        return False

    # ê°€ê²© íŒíŠ¸: baseline ëŒ€ë¹„ ê·¹ì €ê°€ë©´ ì•¡ì„¸ì„œë¦¬ë¡œ ê°€ì¤‘
    if price is not None and baseline_mean:
        if price < max(50_000, baseline_mean * 0.25):
            return True

    # ê¸°ë³¸: ì•¡ì„¸ì„œë¦¬ë¡œ ê°„ì£¼
    return True


############################################################
# 3. ì¹´í…Œê³ ë¦¬ë³„ ê°€ê²© ê°€ë“œ
############################################################

CATEGORY_PRICE_GUARD = {
    IPHONE:      {"min": 30_000,   "max": 5_000_000},
    IPAD:        {"min": 30_000,   "max": 4_000_000},
    MACBOOK:     {"min": 100_000,  "max": 8_000_000},
    APPLE_WATCH: {"min": 20_000,   "max": 2_000_000},
    AIRPODS:     {"min": 10_000,   "max": 800_000},
}


############################################################
# 4. ìƒëŒ€ ì‹œê°„ â†’ UTC ë³€í™˜ + ìœ„ì¹˜ íŒŒì‹±
############################################################

REL_TIME_PAT = re.compile(r"(\d+)\s*(ì´ˆ|ë¶„|ì‹œê°„|ì¼|ì£¼|ê°œì›”|ë‹¬)\s*ì „")


def parse_relative_time_to_utc(rel: str) -> Optional[datetime]:
    if not rel:
        return None
    m = REL_TIME_PAT.search(rel)
    if not m:
        return None

    val = int(m.group(1))
    unit = m.group(2)

    if unit == "ì´ˆ":
        delta = timedelta(seconds=val)
    elif unit == "ë¶„":
        delta = timedelta(minutes=val)
    elif unit == "ì‹œê°„":
        delta = timedelta(hours=val)
    elif unit == "ì¼":
        delta = timedelta(days=val)
    elif unit == "ì£¼":
        delta = timedelta(days=7 * val)
    elif unit in ("ê°œì›”", "ë‹¬"):
        delta = timedelta(days=30 * val)
    else:
        return None

    return datetime.utcnow() - delta


def extract_location_and_time(li: BeautifulSoup):
    """
    li í•˜ë‚˜ì—ì„œ 'ë…¼í˜„1ë™', '1ì‹œê°„ ì „' ê°™ì€ ìœ„ì¹˜/ì‹œê°„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    """
    location_text = None
    time_text = None

    info_div = li.select_one("div.mt-1.mb-2, div[class*='mt-1'][class*='mb-2']")
    if info_div:
        spans = info_div.find_all("span")
    else:
        spans = li.find_all("span")

    for span in spans:
        txt = span.get_text(strip=True)
        if not txt or txt == "|":
            continue

        if REL_TIME_PAT.search(txt):
            time_text = txt
        elif any(suffix in txt for suffix in ["ë™", "êµ¬", "ì‹œ", "ì", "ë©´", "ë¦¬"]) and "ì „" not in txt:
            if location_text is None:
                location_text = txt

    return location_text, time_text


def split_admin_from_location(
    raw_location: Optional[str],
    sd_hint: Optional[str] = None,
    sgg_hint: Optional[str] = None,
):
    """
    raw_location ì˜ˆ:
      - 'ë…¼í˜„1ë™'
      - 'ê°•ë‚¨êµ¬ ì—­ì‚¼ë™'
      - 'ì„œìš¸ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™'
    ë¥¼ (sd, sgg, emd) ë¡œ ë¶„ë¦¬. hint ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©.
    """
    sd = sd_hint or ""
    sgg = sgg_hint or ""
    emd = ""

    if not raw_location:
        return sd, sgg, emd

    parts = raw_location.split()
    if len(parts) == 1:
        emd = parts[0]
    elif len(parts) == 2:
        if not sgg:
            sgg = parts[0]
        emd = parts[1]
    else:
        if not sd:
            sd = parts[0]
        if not sgg:
            sgg = parts[1]
        emd = parts[-1]

    return sd, sgg, emd


############################################################
# 5. Selenium ë“œë¼ì´ë²„
############################################################

def create_driver(headless: bool = True) -> webdriver.Chrome:
    opts = Options()
    if headless:
        opts.add_argument("--headless")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1920,1080")
    return webdriver.Chrome(options=opts)


############################################################
# 6. HTML íŒŒì„œ(í•œ í˜ì´ì§€)
############################################################

def parse_joongna_search_html(
    html: str,
    category_id: int,
    sd_hint: Optional[str],
    sgg_hint: Optional[str],
    last_crawled_at_iso: str,
):
    """
    ê²€ìƒ‰ ê²°ê³¼ HTML í•œ í˜ì´ì§€ â†’ ìŠ¤í™ì— ë§ëŠ” dict ë¦¬ìŠ¤íŠ¸.
    """
    soup = BeautifulSoup(html, "html.parser")
    items: List[Dict] = []

    grid = soup.select_one("ul.grid")
    if not grid:
        print("âš ï¸ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸(ul.grid)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return [], False  # items, found_any_product

    found_any_product = False

    for li in grid.select("li"):
        a_tag = li.select_one("a[href*='/product/']")
        if not a_tag:
            continue

        href = a_tag.get("href", "")
        if not href or "/product/form" in href:
            continue

        found_any_product = True

        url = urljoin(BASE_URL, href)
        external_id = url.split("/")[-1].split("?")[0]

        # ì œëª©
        title_tag = li.select_one("h2, p.font-semibold, p.line-clamp-2")
        title = title_tag.get_text(strip=True) if title_tag else ""
        if not title:
            continue

        # ê´‘ê³  í•„í„°
        if is_advertisement(title):
            continue

        # ê°€ê²©
        price_tag = li.select_one("div.font-semibold, p.text-gray-900, p[class*='price']")
        raw_price = price_tag.get_text(strip=True) if price_tag else ""
        digits = re.sub(r"[^0-9]", "", raw_price)
        price = int(digits) if digits else 0

        # ì¹´í…Œê³ ë¦¬ë³„ ê°€ê²© ê°€ë“œ
        guard = CATEGORY_PRICE_GUARD.get(category_id)
        if guard:
            if price < guard["min"] or price > guard["max"]:
                continue

        # ì•¡ì„¸ì„œë¦¬ í•„í„°
        if is_accessory_title(title, category_id, price, baseline_mean=None):
            continue

        # ìœ„ì¹˜/ì‹œê°„
        loc_text, rel_time_text = extract_location_and_time(li)
        sd, sgg, emd = split_admin_from_location(loc_text, sd_hint=sd_hint, sgg_hint=sgg_hint)

        posted_at_iso = ""
        if rel_time_text:
            dt = parse_relative_time_to_utc(rel_time_text)
            if dt:
                posted_at_iso = dt.isoformat(timespec="seconds") + "Z"

        posted_updated_at_iso = ""  # ì •ë³´ ì—†ìŒ

        item = {
            "source": "joongna",
            "external_id": external_id,
            "category_id": category_id,
            "title": title,
            "price": price,
            "url": url,
            "status": "active",
            "sd": sd,
            "sgg": sgg,
            "emd": emd,
            "posted_at": posted_at_iso,
            "posted_updated_at": posted_updated_at_iso,
            "last_crawled_at": last_crawled_at_iso,
        }

        items.append(item)

    return items, found_any_product


############################################################
# 7. í‚¤ì›Œë“œ(êµ¬ + ì¹´í…Œê³ ë¦¬ëª…) ë‹¨ìœ„ í¬ë¡¤ë§
############################################################

def crawl_keyword(
    driver: webdriver.Chrome,
    keyword: str,
    category_id: int,
    sd_hint: str,
    sgg_hint: str,
    max_pages: int = 20,
    sleep_range: tuple = (0.5, 1.5),
):
    """
    ì˜ˆ) keyword = 'ê°•ë‚¨êµ¬ ì•„ì´í°'
    ìµœì‹ ìˆœ ì •ë ¬ + í˜ì´ì§€ ëê¹Œì§€.
    """
    encoded = quote(keyword)
    base_url = f"{BASE_URL}/search/{encoded}?keywordSource=INPUT_KEYWORD&sort=RECENT_SORT"

    all_items: List[Dict] = []
    last_crawled_at_iso = datetime.utcnow().isoformat(timespec="seconds") + "Z"

    for page in range(1, max_pages + 1):
        if page == 1:
            url = base_url
        else:
            url = f"{base_url}&page={page}"

        print(f"[PAGE] {url}")
        driver.get(url)

        # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë¡œë”© ê¸°ë‹¤ë¦¬ê¸°
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "ul.grid li"))
            )
        except Exception:
            print("  âš ï¸ ul.grid li ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ í˜ì´ì§€ëŠ” ë¹„ì–´ìˆëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì¤‘ë‹¨.")
            break

        time.sleep(1.5)

        html = driver.page_source
        page_items, found_any_product = parse_joongna_search_html(
            html=html,
            category_id=category_id,
            sd_hint=sd_hint,
            sgg_hint=sgg_hint,
            last_crawled_at_iso=last_crawled_at_iso,
        )

        # ì´ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ì¹´ë“œ ìì²´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ â†’ ì´ (êµ¬, ì¹´í…Œê³ ë¦¬) ë.
        if not found_any_product:
            print("  âš ï¸ ë” ì´ìƒ ìƒí’ˆ ì¹´ë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ì´ë™.")
            break

        print(f"  âœ… ìœ íš¨ ìƒí’ˆ {len(page_items)}ê°œ ì¶”ì¶œ")
        all_items.extend(page_items)

        # í˜ì´ì§€ë³„ ë”œë ˆì´
        time.sleep((sleep_range[0] + sleep_range[1]) / 2.0)

    return all_items


############################################################
# 8. ë©”ì¸ ì‹¤í–‰ë¶€ (êµ¬ í•˜ë‚˜ ëë‚  ë•Œë§ˆë‹¤ CSV append)
############################################################

def main():
    parser = argparse.ArgumentParser(description="ì¤‘ê³ ë‚˜ë¼ ì„œìš¸ 25ê°œêµ¬ Ã— ì¹´í…Œê³ ë¦¬ í¬ë¡¤ëŸ¬")
    parser.add_argument(
        "--category",
        type=str,
        default="all",
        help="í¬ë¡¤ë§í•  ì¹´í…Œê³ ë¦¬ëª… (ì•„ì´í°, ì•„ì´íŒ¨ë“œ, ë§¥ë¶, ì• í”Œì›Œì¹˜, ì—ì–´íŒŸ, all)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="items_raw_seoul_joongna.csv",
        help="ì¶œë ¥ CSV íŒŒì¼ëª…",
    )
    parser.add_argument(
        "--max-pages",
        type=int,
        default=20,
        help="êµ¬Ã—ì¹´í…Œê³ ë¦¬ ì¡°í•©ë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜(ê¸°ë³¸ 20)",
    )
    parser.add_argument(
        "--no-headless",
        action="store_true",
        help="ë¸Œë¼ìš°ì € ì°½ ë„ìš°ê¸°",
    )

    args = parser.parse_args()

    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    if args.category == "all":
        target_categories = list(CATEGORY_MAP.items())  # (ì´ë¦„, id)
    else:
        if args.category not in CATEGORY_MAP:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬ëª…: {args.category}")
        target_categories = [(args.category, CATEGORY_MAP[args.category])]

    # CSV í—¤ë”ë¥¼ ë¨¼ì € í•œ ë²ˆë§Œ ì¨ë‘ê¸° (ë§¤ ì‹¤í–‰ë§ˆë‹¤ ìƒˆë¡œ ìƒì„±)
    fieldnames = [
        "source",
        "external_id",
        "category_id",
        "title",
        "price",
        "url",
        "status",
        "sd",
        "sgg",
        "emd",
        "posted_at",
        "posted_updated_at",
        "last_crawled_at",
    ]
    with open(args.output, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
    print(f"ğŸ“„ ìƒˆ CSV ìƒì„± ë° í—¤ë” ì‘ì„±: {args.output}")

    driver = create_driver(headless=not args.no_headless)
    total_count = 0  # ì „ì²´ ëˆ„ì  ê°œìˆ˜

    try:
        for category_name, category_id in target_categories:
            print("\n" + "=" * 60)
            print(f"â–¶ ì¹´í…Œê³ ë¦¬: {category_name} (id={category_id}) í¬ë¡¤ë§ ì‹œì‘")
            print("=" * 60)

            for gu in SEOUL_DISTRICTS:
                keyword = f"{gu} {category_name}"
                print(
                    f"\n------------------------------\n"
                    f" [í‚¤ì›Œë“œ] {keyword}\n"
                    f"------------------------------"
                )

                items = crawl_keyword(
                    driver=driver,
                    keyword=keyword,
                    category_id=category_id,
                    sd_hint="ì„œìš¸íŠ¹ë³„ì‹œ",
                    sgg_hint=gu,
                    max_pages=args.max_pages,
                )

                print(f"  â†’ {keyword} ì—ì„œ ìµœì¢… {len(items)}ê°œ ìˆ˜ì§‘")

                # âœ… ì—¬ê¸°ì„œ ë°”ë¡œ CSVì— append
                if items:
                    with open(args.output, "a", newline="", encoding="utf-8-sig") as f:
                        writer = csv.DictWriter(f, fieldnames=fieldnames)
                        for row in items:
                            writer.writerow(row)
                    total_count += len(items)
                    print(f"  ğŸ“ {args.output} ì— {len(items)}ê°œ í–‰ ì¶”ê°€ (ëˆ„ì  {total_count}ê°œ)")
                else:
                    print("  âš ï¸ ì €ì¥í•  ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤ (ì´ í‚¤ì›Œë“œ ìŠ¤í‚µ).")

        print("\n" + "=" * 60)
        print(f"âœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ. ìµœì¢… ëˆ„ì  row ìˆ˜: {total_count}")
        print(f"âœ… ê²°ê³¼ íŒŒì¼: {args.output}")
        print("=" * 60)

    finally:
        try:
            driver.quit()
        except Exception:
            pass
        print("ğŸ”’ WebDriver ì¢…ë£Œ")


if __name__ == "__main__":
    main()
